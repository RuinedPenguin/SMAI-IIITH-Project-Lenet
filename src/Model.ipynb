{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f4ZLz--mWKeo"
   },
   "outputs": [],
   "source": [
    "# import cupy as np\n",
    "# when gpu, in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wpl18ZkLxMln"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# when cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gIBwhswFeciT"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "D4uKoBvUWXxS"
   },
   "outputs": [],
   "source": [
    "# pip install zope\n",
    "# import zope.interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract class Function for creating activation function objects, to be used in different Layers\n",
    "class Functions(ABC):\n",
    "    # abstract method 'apply', used in forward passes\n",
    "    @abstractmethod\n",
    "    def apply(self, x):\n",
    "        pass\n",
    "\n",
    "    # abstract method 'gradient', used in backpropogation\n",
    "    @abstractmethod\n",
    "    def gradient(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default function for any layer, f(x) = x\n",
    "class Basic(Functions):\n",
    "    def apply(self, x):\n",
    "        return x\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        if isinstance(x, np.darray):\n",
    "            return np.ones(x.shape)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "class Sigmoid(Functions):\n",
    "    def apply(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        s = self.apply(x)\n",
    "        return s*(1-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperbolic tangent function\n",
    "class Tanh(Functions):\n",
    "    def __init__(self, A = 1, S = 1):\n",
    "        self.A = A\n",
    "        self.S = S\n",
    "        \n",
    "    def apply(self, x):\n",
    "        return self.A * np.tanh(self.S * x)\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return (1 - (self.apply(x))**2) * self.S * self.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7n3fxvn2bPe4"
   },
   "outputs": [],
   "source": [
    "# abstract class Layer, whih provides the basic structure to be followed all the different types of layers\n",
    "class Layer(ABC):\n",
    "    # ever child class must have an activation function, default is Basic\n",
    "    def __init__(self, function = Basic()):\n",
    "        self.function = function\n",
    "        \n",
    "    # abstract method, useful for initialising weights and biases according to the shapes\n",
    "    # returns output shape of the layer\n",
    "    @abstractmethod\n",
    "    def initialise_weights(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    # abstract method, useful for defining the forward calculations of the layer\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    # abstract method, useful for defining the backpropogation calculations and updating weights\n",
    "    @abstractmethod\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "59lEduBBWipM"
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer\n",
    "class Conv(Layer):\n",
    "#    kernel shape - k - tuple of size 2 or 3, egs-> (3,3) or (3,3,2), \n",
    "#    output channels - c_out - int\n",
    "#    and the activation function - function - Function\n",
    "#    can be modified to add strides - s, if needed\n",
    "    def __init__(self, k, c_out, function = Basic()):\n",
    "        self.k = k\n",
    "        self.c_out = c_out\n",
    "        self.kernels = []\n",
    "        super().__init__(function)\n",
    "        # self.s = s\n",
    "\n",
    "#    initialises c_out different kernels of shape k with uniformly distributed random weights\n",
    "    def initialise_weights(self, input_shape):\n",
    "        if len(self.k) == 2:\n",
    "            h,w = self.k\n",
    "            c = 0\n",
    "        else:\n",
    "            h,w,c = self.k\n",
    "    \n",
    "        for i in range(self.c_out):\n",
    "            if (c == 0):\n",
    "                self.kernels.append(np.random.rand(h,w))\n",
    "            else:\n",
    "                self.kernels.append(np.random.rand(h,w,c))\n",
    "\n",
    "        return (input_shape[0] - self.k[0] + 1, \n",
    "                input_shape[1] - self.k[1] + 1, \n",
    "                self.c_out)\n",
    "\n",
    "#    scratch implementation of the convolutional forward pass, with an activation function applied at the end\n",
    "    def forward(self, x):\n",
    "        new_h = x.shape[0] - self.k[0] + 1\n",
    "        new_w = x.shape[1] - self.k[1] + 1\n",
    "\n",
    "        # if self.c_out == 1:\n",
    "        #   return convolve(x, self.kernels[0], new_h, new_w)\n",
    "\n",
    "        out = np.zeros((new_h, new_w, self.c_out))\n",
    "        for i in range(self.c_out):\n",
    "            out[:,:,i] = self.convolve(x, i, new_h, new_w)\n",
    "\n",
    "        return self.function.apply(out)\n",
    "\n",
    "#    basic implementaion of a convolutional operation, used in forward pass\n",
    "    def convolve(self, inp, kernel_no, new_h, new_w):\n",
    "        kernel = self.kernels[kernel_no]\n",
    "        out_c = np.zeros((new_h, new_w))\n",
    "\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                out_c[i,j] = np.sum(inp[i : i + kernel.shape[0], j : j + kernel.shape[1]] * kernel)\n",
    "\n",
    "        return out_c\n",
    "\n",
    "#    to be implemented\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OEXum7L6JAgO"
   },
   "outputs": [],
   "source": [
    "# abstract parent class to implement Pooling\n",
    "class Pool(Layer):\n",
    "#    pool kernel shape - k - tuple of size 2\n",
    "#    activation function - function\n",
    "    def __init__(self, k, function = Basic()):\n",
    "        self.k = k\n",
    "        super().__init__(function)\n",
    "        # self.s = s\n",
    "\n",
    "#    normally pooling layers don't have trainable parameters, so doesn't initialise anything\n",
    "#    returns output shape\n",
    "    def initialise_weights(self, input_shape):\n",
    "        if len(input_shape) == 2:\n",
    "            return (input_shape[0] // self.k, input_shape[1] // self.k)\n",
    "\n",
    "        return (input_shape[0] // self.k, input_shape[1] // self.k, \n",
    "                input_shape[2])\n",
    "    \n",
    "#    does a basic forward pass\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 2:\n",
    "            return self.pool_2d(x)\n",
    "\n",
    "        out = np.zeros((x.shape[0] // self.k, x.shape[1] // self.k, x.shape[2]))\n",
    "        for i in range(x.shape[2]):\n",
    "            out[:,:,i] = self.pool_2d(x[:,:,i])\n",
    "\n",
    "        return self.function.apply(out)\n",
    "\n",
    "#    applies the specified pooling function, to a single channel\n",
    "    def pool_2d(self, x_2d):\n",
    "        out = np.zeros((x_2d.shape[0] // self.k, x_2d.shape[1] // self.k))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                h = i * self.k\n",
    "                w = j * self.k\n",
    "                out[i,j] = self.pooling_function(x_2d[h:h+self.k, w:w+self.k])\n",
    "\n",
    "        return out\n",
    "\n",
    "#    abstract method, lets children classes specify different pooling functions\n",
    "    @abstractmethod\n",
    "    def pooling_function(self, matrix):\n",
    "        pass\n",
    "\n",
    "#    to be implemented\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XFQp13qq7qqg"
   },
   "outputs": [],
   "source": [
    "# A pooling layer, with trainable parameters\n",
    "class Subsampling(Pool):\n",
    "    \n",
    "#    initialises n different weights and biases which are random and uniformly distributed, n = input channels\n",
    "    def initialise_weights(self, input_shape):\n",
    "        n = 1 if len(input_shape) == 2 else input_shape[2]\n",
    "        self.w = np.random.rand(n)\n",
    "        self.b = np.random.rand(n)\n",
    "#         print(input_shape)\n",
    "        return super().initialise_weights(input_shape)\n",
    "\n",
    "#    returns sum of the matrix\n",
    "    def pooling_function(self, matrix):\n",
    "        return np.sum(matrix)\n",
    "\n",
    "#    forward pass, w * sum() + b\n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "\n",
    "        if len(out.shape) == 2:\n",
    "            return out * self.w[0] + self.b[0]\n",
    "\n",
    "        for i in range(out.shape[2]):\n",
    "            out[:,:,i] = out[:,:,i] * self.w[i] + self.b[i]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XXVTDuEDBX4I"
   },
   "outputs": [],
   "source": [
    "# class MaxPool(Pool):\n",
    "#     def __init__(self, k):\n",
    "#         super().__init__(k)\n",
    "\n",
    "#     def pooling_function(self, matrix):\n",
    "#         return np.max(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1tSRpVpABYCr"
   },
   "outputs": [],
   "source": [
    "# Flattens the input\n",
    "class Flatten(Layer):\n",
    "#    no weights in the picture, returns output shape\n",
    "    def initialise_weights(self, input_shape):\n",
    "        out_shape = 1\n",
    "        for i in input_shape:\n",
    "            out_shape *= i\n",
    "        return (out_shape,1)\n",
    "\n",
    "#    reshapes the input x to a column vector\n",
    "    def forward(self, x):\n",
    "        return x.reshape((-1,1))\n",
    "\n",
    "#    to be implemented\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MEfQLF8OwWTX"
   },
   "outputs": [],
   "source": [
    "# Fully Connected Layer\n",
    "class Fully_Connected(Layer):\n",
    "#    no. of neural units - units - int\n",
    "#    activation function - function - Function\n",
    "    def __init__(self, units, function = Basic()):\n",
    "        self.units = units\n",
    "        self.weights = None\n",
    "        super().__init__(function)\n",
    "\n",
    "#    initialises a matrix of weights, including biases, of shape (units, input + 1)\n",
    "    def initialise_weights(self, input_shape):\n",
    "        self.weights = np.random.rand(self.units, input_shape[0] + 1)\n",
    "        return (self.units,1)\n",
    "\n",
    "#    basic forward pass, returns units number of outputs\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1,1))\n",
    "        out = np.dot(self.weights, np.vstack((x,1)))\n",
    "        return self.function.apply(out)\n",
    "\n",
    "#    to be implemented\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2B2vqFRJlFOO"
   },
   "outputs": [],
   "source": [
    "# a special layer, uses the euclidean distance between the input vector and its parameter vector\n",
    "class RBF(Layer):\n",
    "#    no. of neural units - units - int\n",
    "#    activation function - function - Function\n",
    "    def __init__(self, units, function = Basic()):\n",
    "        self.units = units\n",
    "        self.weights = None\n",
    "        super().__init__(function)\n",
    "\n",
    "#    initialises a matrix of weights, of shape (units, input)\n",
    "    def initialise_weights(self, input_shape):\n",
    "        self.weights = np.random.rand(self.units, input_shape[0])\n",
    "        return (self.units,1)\n",
    "\n",
    "#    does a basic forward pass, calcualtes the eulidean distances, and applies the activation function\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1,1))\n",
    "        out = self.weights - x.T\n",
    "        out = np.square(out)\n",
    "        out = np.sum(out, axis = 1)\n",
    "        return self.function.apply(out)\n",
    "\n",
    "#    to be implemented\n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jbC2DmolWvhn"
   },
   "outputs": [],
   "source": [
    "# Model class, to define a model by adding layers, train and test data\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.compiled = False\n",
    "\n",
    "#    adds a layer to the list\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.compiled = False\n",
    "\n",
    "#    removes the layer at index\n",
    "    def remove(self, index):\n",
    "        self.list.pop(index)\n",
    "        self.compiled = False\n",
    "\n",
    "#    inialises the weights of all the layers and checks whether the output shape matches with the expected\n",
    "    def compile(self, x_shape, y_shape, print_shapes = False):\n",
    "        input_shape = x_shape\n",
    "        for layer in self.layers:\n",
    "            if print_shapes:\n",
    "                print(input_shape, layer)\n",
    "            input_shape = layer.initialise_weights(input_shape)\n",
    "\n",
    "            if print_shapes:\n",
    "                print(\"Output\", input_shape)\n",
    "\n",
    "        if input_shape == y_shape:\n",
    "            print(\"The layers fit correctly\")\n",
    "            self.compiled = True\n",
    "        else:\n",
    "            print(\"The layers don't fit correctly\")\n",
    "            self.compiled = False\n",
    "            \n",
    "#    INCOMPLETE, backpropogation part is yet to be added\n",
    "#    used for training the model\n",
    "    def fit(self, x_train, y_train, epochs, validation_data):\n",
    "        if not self.compiled:\n",
    "            print(\"Compilation needed\")\n",
    "            return\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            layer_in = x_train\n",
    "            outputs = [layer]\n",
    "\n",
    "            for layer in self.layers:\n",
    "                layer_in = layer.forward(layer_in)\n",
    "\n",
    "            print(\"Model Trained\")\n",
    "\n",
    "#    runs the current model on the input dataset\n",
    "#    used for testing the model\n",
    "    def test(self, x_test):\n",
    "        if not self.compiled:\n",
    "            print(\"Compilation needed\")\n",
    "            return\n",
    "        \n",
    "        outputs = []\n",
    "\n",
    "        for i in range(x_test.shape[0]):\n",
    "            layer_in = x_test[i]\n",
    "#             print(layer_in.shape)\n",
    "            for layer in self.layers:\n",
    "                layer_in = layer.forward(layer_in)\n",
    "            outputs.append(layer_in)\n",
    "\n",
    "        return np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4vvdwD4WvpI"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNvg58pG7k/SPEImkZTsdiu",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Lenet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
